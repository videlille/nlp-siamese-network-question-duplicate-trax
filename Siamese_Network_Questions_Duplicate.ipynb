{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTFsqRmA9TAl"
      },
      "source": [
        "# Siamese Network - Question duplicate\n",
        "\n",
        "Objective: \n",
        "\n",
        "Dataset: Quora Question pairs https://www.kaggle.com/c/quora-question-pairs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-2kgpdr9TAp"
      },
      "source": [
        "Notes : \n",
        "- SNNs won’t output the probabilities of the prediction, only distance from each class.\n",
        "- Since training SNNs involve pairwise learning, we cannot use cross entropy loss cannot be used. There are two loss functions we typically use to train siamese networks: triplet loss and contrastive loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install trax"
      ],
      "metadata": {
        "id": "JCZC6BJDDd09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trax\n",
        "import trax"
      ],
      "metadata": {
        "id": "Jhhgg0eaBOor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5497f664-2c13-465c-e3d3-f019c31e7ab3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgfNwxSl9TAq",
        "outputId": "f3fa75a9-9004-44e2-fe1d-60ed1d1fdf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "from trax.fastmath import numpy as fastnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rnd\n",
        "from trax import shapes\n",
        "\n",
        "# set random seeds\n",
        "RANDOM_SEED=42\n",
        "rnd.seed(34)\n",
        "\n",
        "# We need to download the punkt data to be able to tokenize our sentences.\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih6y_9uE9TAt"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "1sKo0fTX9TAt",
        "outputId": "aa427eb6-f525-455d-dd3e-831b134aac66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of question pairs:  404290\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83da21e7-ecd9-4452-ae2a-b67dcf8aac58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83da21e7-ecd9-4452-ae2a-b67dcf8aac58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83da21e7-ecd9-4452-ae2a-b67dcf8aac58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83da21e7-ecd9-4452-ae2a-b67dcf8aac58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "N=len(data)\n",
        "print('Number of question pairs: ', N)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtxEh6Ry9TAu"
      },
      "source": [
        "Divide between train/test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpP_DNRs9TAv",
        "outputId": "4d966609-16c3-4971-c3c7-7d96e49dad50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 300000 Test set: 10240\n"
          ]
        }
      ],
      "source": [
        "N_train = 300000\n",
        "N_test  = 10*1024\n",
        "data_train = data[:N_train]\n",
        "data_test  = data[N_train:N_train+N_test]\n",
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
        "del(data) # remove to free memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UBr5Eg19TAw"
      },
      "source": [
        "Filtering out non-duplicates. Two batches Q1 and Q2 are built. \n",
        "-  q1i == q2i  \n",
        "-  q1i =/= q2j if i=/=j  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3vb-AIY9TAx",
        "outputId": "c0ba9b5c-c4ce-4ac6-9703-cebf4a529b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of duplicate questions:  111473\n",
            "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
          ]
        }
      ],
      "source": [
        "td_index = (data_train['is_duplicate'] == 1).to_numpy()\n",
        "td_index = [i for i, x in enumerate(td_index) if x] \n",
        "print('number of duplicate questions: ', len(td_index))\n",
        "print('indexes of first ten duplicate questions:', td_index[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4HdKiIv9TAx"
      },
      "source": [
        "One example of duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJA4gdfV9TAy",
        "outputId": "eaabf559-baaf-4888-f97a-2f817f11dc67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How can I be a good geologist?\n",
            "What should I do to be a great geologist?\n",
            "is_duplicate:  1\n"
          ]
        }
      ],
      "source": [
        "print(data_train['question1'][7])  \n",
        "print(data_train['question2'][7])\n",
        "print('is_duplicate: ', data_train['is_duplicate'][7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOli11ic9TAy"
      },
      "source": [
        "Training and test dataset. the training dataset only contains duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KVaqEHQ-9TAz"
      },
      "outputs": [],
      "source": [
        "Q1_train_words = np.array(data_train['question1'][td_index])\n",
        "Q2_train_words = np.array(data_train['question2'][td_index])\n",
        "\n",
        "Q1_test_words = np.array(data_test['question1'])\n",
        "Q2_test_words = np.array(data_test['question2'])\n",
        "y_test  = np.array(data_test['is_duplicate'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5wy_BaJ9TAz"
      },
      "source": [
        "Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYNlThrv9TA0",
        "outputId": "529f0d9e-d0e2-44d7-e249-1a53ffa20b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING QUESTIONS:\n",
            "\n",
            "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
            "\n",
            "Question 1:  What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
            "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
            "\n",
            "TESTING QUESTIONS:\n",
            "\n",
            "Question 1:  What were some of the troubles you have faced during and after your 9 months period of pregnancy?\n",
            "Question 2:  What is the difference between neural circuit and neural system? \n",
            "\n",
            "is_duplicate = 0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('TRAINING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_train_words[0])\n",
        "print('Question 2: ', Q2_train_words[0], '\\n')\n",
        "print('Question 1: ', Q1_train_words[5])\n",
        "print('Question 2: ', Q2_train_words[5], '\\n')\n",
        "\n",
        "print('TESTING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_test_words[0])\n",
        "print('Question 2: ', Q2_test_words[0], '\\n')\n",
        "print('is_duplicate =', y_test[0], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwrIsXd9TA0"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M9us23I9TA1"
      },
      "source": [
        "### Build the vocabulary\n",
        "\n",
        "We build the vocabulary by mapping the words to the \"index\" for that word in the dictionary. For all out Out of Vocabulary words, the index 0 is assigned.\n",
        "Questions are encoded as q list of numbers.\n",
        "Pad value at 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YQSLaD0l9TA1"
      },
      "outputs": [],
      "source": [
        "#create arrays\n",
        "Q1_train = np.empty_like(Q1_train_words)\n",
        "Q2_train = np.empty_like(Q2_train_words)\n",
        "\n",
        "Q1_test = np.empty_like(Q1_test_words)\n",
        "Q2_test = np.empty_like(Q2_test_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWevW_9q9TA1",
        "outputId": "a8178aeb-2f4f-42dc-b6d7-ad2db39d3ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the vocabulary is:  36279\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "vocab = defaultdict(lambda: 0)\n",
        "vocab['<PAD>'] = 1\n",
        "\n",
        "for idx in range(len(Q1_train_words)):\n",
        "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n",
        "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
        "    q = Q1_train[idx] + Q2_train[idx]\n",
        "    for word in q:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab) + 1\n",
        "print('The length of the vocabulary is: ', len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IznlwHhp9TA2",
        "outputId": "1755cd85-2981-4896-fada-ce27459f4ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "8645\n",
            "1774\n"
          ]
        }
      ],
      "source": [
        "print(vocab['<PAD>'])\n",
        "print(vocab['geology'])\n",
        "print(vocab['history'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ku8nZVX89TA2"
      },
      "outputs": [],
      "source": [
        "for idx in range(len(Q1_test_words)): \n",
        "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
        "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLrMn5vg9TA2",
        "outputId": "dd68f7e2-f9dd-4602-c082-7b7e86f09c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set has reduced to:  111473\n",
            "Test set length:  10240\n"
          ]
        }
      ],
      "source": [
        "print('Train set has reduced to: ', len(Q1_train) ) \n",
        "print('Test set length: ', len(Q1_test) ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr7uHdNH9TA3"
      },
      "source": [
        "### Convering question to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XLyxTqee9TA3"
      },
      "outputs": [],
      "source": [
        "# Converting questions to array of integers\n",
        "for i in range(len(Q1_train)):\n",
        "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
        "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
        "\n",
        "        \n",
        "for i in range(len(Q1_test)):\n",
        "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
        "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl6xVY3N9TA4",
        "outputId": "83a30531-009f-4c11-988d-c43a6f8a54b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first question in the train set:\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
            "\n",
            "encoded version:\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
            "\n",
            "first question in the test set:\n",
            "\n",
            "What were some of the troubles you have faced during and after your 9 months period of pregnancy? \n",
            "\n",
            "encoded version:\n",
            "[30, 271, 116, 131, 78, 28828, 53, 218, 6589, 124, 11, 267, 56, 1636, 606, 2092, 131, 4329, 21]\n"
          ]
        }
      ],
      "source": [
        "print('first question in the train set:\\n')\n",
        "print(Q1_train_words[0], '\\n') \n",
        "print('encoded version:')\n",
        "print(Q1_train[0],'\\n')\n",
        "\n",
        "print('first question in the test set:\\n')\n",
        "print(Q1_test_words[0], '\\n')\n",
        "print('encoded version:')\n",
        "print(Q1_test[0]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS-lvAPU9TA4"
      },
      "source": [
        "### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tmnE6LES9TA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5323838-1ef2-4afa-c81c-6732c9020ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate questions:  111473\n",
            "The length of the training set is:   89178\n",
            "The length of the validation set is:  22295\n"
          ]
        }
      ],
      "source": [
        "# Splitting the data\n",
        "TRAINING_FRACTION = 0.8\n",
        "\n",
        "cut_off = int(len(Q1_train)*TRAINING_FRACTION)\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
        "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n",
        "print('Number of duplicate questions: ', len(Q1_train))\n",
        "print(\"The length of the training set is:  \", len(train_Q1))\n",
        "print(\"The length of the validation set is: \", len(val_Q1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cha5ioJ39TA5"
      },
      "source": [
        "### Data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "we7dkUgw9TA5"
      },
      "outputs": [],
      "source": [
        "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
        "    \"\"\"Generator function that yields batches of data\n",
        "\n",
        "    Args:\n",
        "        Q1 (list): List of transformed (to tensor) questions.\n",
        "        Q2 (list): List of transformed (to tensor) questions.\n",
        "        batch_size (int): Number of elements per batch.\n",
        "        pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
        "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
        "    Yields:\n",
        "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
        "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
        "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
        "    \"\"\"\n",
        "\n",
        "    input1 = []\n",
        "    input2 = []\n",
        "    idx = 0\n",
        "    len_q = len(Q1)\n",
        "    question_indexes = [*range(len_q)]\n",
        "    \n",
        "    if shuffle:\n",
        "        rnd.shuffle(question_indexes)\n",
        "    \n",
        "    while True:\n",
        "        if idx >= len_q:\n",
        "            # if idx is greater than or equal to len_q, set idx accordingly \n",
        "\n",
        "            idx = 0\n",
        "            # shuffle to get random batches if shuffle is set to True\n",
        "            if shuffle:\n",
        "                rnd.shuffle(question_indexes) \n",
        "        \n",
        "        # get questions at the `question_indexes[idx]` position in Q1 and Q2\n",
        "        q1 = Q1[question_indexes[idx]]\n",
        "        q2 = Q2[question_indexes[idx]]\n",
        "\n",
        "        idx += 1\n",
        "        input1.append(q1)\n",
        "        input2.append(q2)\n",
        "        if len(input1) == batch_size:\n",
        "            # determine max_len as the longest question in input1 & input 2\n",
        "            max_len = max(max(len(x) for x in input1 ),max(len(x) for x in input2 ))\n",
        "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
        "            b1 = [] \n",
        "            b2 = [] \n",
        "            for q1, q2 in zip(input1, input2):\n",
        "                # add [pad] to q1 until it reaches max_len\n",
        "                q1 = q1 +[vocab['<PAD>']] * (max_len - len(q1))\n",
        "                q2  = q2 +[vocab['<PAD>']] * (max_len - len(q2))                \n",
        "                b1.append(q1)\n",
        "                b2.append(q2)\n",
        "            yield np.array(b1), np.array(b2)\n",
        "            # reset the batches\n",
        "            input1, input2 = [], []  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D73MIOc9TA6"
      },
      "source": [
        "## Siamese network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUVALXNV9TA6"
      },
      "source": [
        "Siamese network using pytorch from: https://github.com/JiHunWang/quora-question-similarity-kaggle/blob/main/model/siameseNetwork.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7l0Fr3609TA7"
      },
      "outputs": [],
      "source": [
        "def Siamese(vocab_size=41699, d_model=128, mode='train'):\n",
        "    \"\"\"Returns a Siamese model.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).\n",
        "        d_model (int, optional): Depth of the model. Defaults to 128.\n",
        "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Parallel: A Siamese model. \n",
        "    \"\"\"\n",
        "\n",
        "    def normalize(x):  # normalizes the vectors to have L2 norm 1\n",
        "        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n",
        "    \n",
        "\n",
        "    q_processor = tl.Serial( # Processor will run on Q1 and Q2. \n",
        "        tl.Embedding(vocab_size, d_model), # Embedding layer\n",
        "        tl.LSTM(d_model), # LSTM layer\n",
        "        tl.Mean(axis=1), # Mean over columns\n",
        "        tl.Fn('Normalize', lambda x: normalize(x)), # Apply normalize function\n",
        "    )  # Returns one vector of shape [batch_size, d_model]. \n",
        "    \n",
        "\n",
        "    model = tl.Parallel(q_processor, q_processor)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Siamese()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3_xnfTShT91",
        "outputId": "90cc6d8a-2917-4b5c-e468-2452974dbd2a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel_in2_out2[\n",
            "  Serial[\n",
            "    Embedding_41699_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "  Serial[\n",
            "    Embedding_41699_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmCXuNlj9TA7"
      },
      "source": [
        "## Triplet loss\n",
        "\n",
        "Triplet loss is composed of two terms. One term utilizes the mean of all the non duplicates, the second utilizes the *closest negative*. Our loss expression is then:\n",
        " \n",
        "\\begin{align}\n",
        " \\mathcal{Loss_{1}(A,P,N)} &=\\max \\left( -cos(A,P)  + mean_{neg} +\\alpha, 0\\right) \\\\\n",
        " \\mathcal{Loss_{2}(A,P,N)} &=\\max \\left( -cos(A,P)  + closest_{neg} +\\alpha, 0\\right) \\\\\n",
        "\\mathcal{Loss(A,P,N)} &= mean(Loss_1 + Loss_2) \\\\\n",
        "\\end{align}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rm1so8iZ9TA7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def TripletLossFn(v1, v2, margin=0.25):\n",
        "    \"\"\"Custom Loss function.\n",
        "\n",
        "    Args:\n",
        "        v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\n",
        "        v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\n",
        "        margin (float, optional): Desired margin. Defaults to 0.25.\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Triplet Loss.\n",
        "    \"\"\"\n",
        "    scores = fastnp.dot(v1, v2.T) # pairwise cosine sim  \n",
        "\n",
        "    # calculate new batch size\n",
        "    batch_size = len(scores)\n",
        "\n",
        "    positive = fastnp.diagonal(scores)  # the positive ones (duplicates)\n",
        "    negative_zero_on_duplicate = np.multiply(np.ones_like(scores) - fastnp.eye(batch_size),scores)\n",
        "    mean_negative = fastnp.sum(negative_zero_on_duplicate,axis=1)/(batch_size - 1)\n",
        "    mask_exclude_positives = (fastnp.identity(batch_size) == 1) | (negative_zero_on_duplicate > positive.reshape(batch_size,1))\n",
        "\n",
        "    negative_without_positive = negative_zero_on_duplicate - mask_exclude_positives*2\n",
        "\n",
        "    closest_negative = negative_without_positive.max(axis=1)\n",
        "    triplet_loss1 = np.maximum(mean_negative - positive + margin, 0)\n",
        "    triplet_loss2 = np.maximum(closest_negative - positive+ margin, 0)\n",
        "    triplet_loss = fastnp.sum(triplet_loss1+triplet_loss2)  \n",
        "\n",
        "    \n",
        "    return triplet_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the triplet loss"
      ],
      "metadata": {
        "id": "ZroEZ4jGhdQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
        "v2 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
        "print(\"Triplet Loss:\", TripletLossFn(v1,v2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkcNGCtLhc2D",
        "outputId": "3f7cf64f-7c48-4401-edc7-5eaaaadbf16f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triplet Loss: 0.7035077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a layer out of the triplet loss"
      ],
      "metadata": {
        "id": "qpTtMjjqCex9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "def TripletLoss(margin=0.25):\n",
        "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n",
        "    return tl.Fn('TripletLoss', triplet_loss_fn)"
      ],
      "metadata": {
        "id": "qFzrtDq9Ce5Q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n",
        "val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\n",
        "print('train_Q1.shape ', train_Q1.shape)\n",
        "print('val_Q1.shape   ', val_Q1.shape)"
      ],
      "metadata": {
        "id": "stqd0bGXCjkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0827db94-9e88-4564-8012-556b794f7d90"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_Q1.shape  (89178,)\n",
            "val_Q1.shape    (22295,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(Siamese, TripletLoss\n",
        "                , train_generator, val_generator, output_dir='model/'):\n",
        "    \"\"\"Training the Siamese Model\n",
        "\n",
        "    Args:\n",
        "        Siamese (function): Function that returns the Siamese model.\n",
        "        TripletLoss (function): Function that defines the TripletLoss loss function.\n",
        "        lr_schedule (function): Trax multifactor schedule function.\n",
        "        train_generator (generator, optional): Training generator. Defaults to train_generator.\n",
        "        val_generator (generator, optional): Validation generator. Defaults to val_generator.\n",
        "        output_dir (str, optional): Path to save model to. Defaults to 'model/'.\n",
        "\n",
        "    Returns:\n",
        "        trax.supervised.training.Loop: Training loop for the model.\n",
        "    \"\"\"\n",
        "    output_dir = os.path.expanduser(output_dir)\n",
        "\n",
        "    train_task = training.TrainTask( \n",
        "        labeled_data=train_generator,      \n",
        "        loss_layer=TripletLoss(),        \n",
        "        optimizer=trax.optimizers.Adam(0.01),         \n",
        "        lr_schedule=trax.lr.warmup_and_rsqrt_decay(400, 0.01) \n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "        labeled_data=val_generator,      \n",
        "        metrics=[TripletLoss()],         \n",
        "    )\n",
        "    \n",
        "\n",
        "    training_loop = training.Loop(Siamese(),\n",
        "                                  train_task,\n",
        "                                  eval_tasks=[eval_task],\n",
        "                                  output_dir=output_dir)\n",
        "\n",
        "    return training_loop"
      ],
      "metadata": {
        "id": "G0UiKEQgCk68"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps = 5\n",
        "training_loop = train_model(Siamese, TripletLoss, train_generator, val_generator)\n",
        "training_loop.run(train_steps)"
      ],
      "metadata": {
        "id": "RlwT7Mp2CppN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "tNxaTOA3CsnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Siamese()\n",
        "model.init_from_file(file_name='model.pkl.gz', weights_only=True, input_signature=shapes.signature(next(train_generator)))"
      ],
      "metadata": {
        "id": "TyMM0e4zCuDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02de124-b4f0-4779-c6c3-8a85f0206276"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((array([[-0.14566694,  0.0690302 ,  0.03528703, ...,  0.04289422,\n",
              "            0.01495273,  0.0295836 ],\n",
              "          [-0.18167959,  0.06158856, -0.02099077, ..., -0.37289554,\n",
              "           -0.41506082, -0.47958568],\n",
              "          [-0.08760101, -0.11774683,  0.10590506, ..., -0.12719558,\n",
              "           -0.29383892, -0.8486252 ],\n",
              "          ...,\n",
              "          [ 0.11879876,  0.13377659,  0.0523452 , ...,  0.08617012,\n",
              "           -0.14278218,  0.03775889],\n",
              "          [ 0.03600347,  0.013896  , -0.12832586, ...,  0.08852937,\n",
              "           -0.02288531,  0.10609501],\n",
              "          [ 0.09160908,  0.0813653 ,  0.14018479, ...,  0.09997971,\n",
              "            0.10666739, -0.10014597]], dtype=float32),\n",
              "   (((), ((), ())),\n",
              "    ((array([[-0.4249619 , -0.44568634,  0.09243102, ...,  0.24510421,\n",
              "              -0.292594  ,  0.06616695],\n",
              "             [-0.00212805,  0.39122954, -0.3265429 , ..., -0.01921497,\n",
              "               0.17920703, -0.2882711 ],\n",
              "             [ 0.26706126,  0.32310218, -0.1436266 , ...,  0.07792609,\n",
              "              -0.07815409, -0.330889  ],\n",
              "             ...,\n",
              "             [-0.05689898,  0.03631225, -0.30812785, ..., -0.33794788,\n",
              "              -0.07204197, -0.05830837],\n",
              "             [-0.1940051 , -0.11773589,  0.11998903, ..., -0.15561193,\n",
              "              -0.26938224, -0.01998222],\n",
              "             [ 0.12214658, -0.02458438,  0.03383644, ..., -0.05007777,\n",
              "               0.07522411,  0.14639619]], dtype=float32),\n",
              "      array([ 0.519688  ,  0.8132275 ,  0.55432695,  0.73024696, -0.11169132,\n",
              "              0.879841  ,  0.78551626,  0.90385884,  0.7444822 ,  0.772756  ,\n",
              "              0.30833954,  1.0486803 ,  0.77396894,  0.6665287 ,  0.95613027,\n",
              "              0.33811468,  0.5951363 ,  0.3140023 ,  0.69841117,  0.689402  ,\n",
              "              0.06597213,  0.9483962 ,  0.83226234,  0.7085764 ,  0.649541  ,\n",
              "              0.5233063 ,  0.77772427,  0.6898735 ,  0.38568577,  0.63886017,\n",
              "              0.8160569 ,  1.0193173 ,  0.671358  ,  0.6593129 ,  0.3465361 ,\n",
              "              1.1597197 ,  0.9893271 ,  0.8419979 ,  0.75174654,  0.86631763,\n",
              "              0.7238059 ,  0.7502131 ,  0.84692544,  0.7218662 ,  0.953784  ,\n",
              "              0.8751998 ,  0.89186007,  0.96908283,  0.78832483,  0.4106766 ,\n",
              "              0.6465368 ,  0.3580451 ,  0.6696191 ,  0.2320964 , -0.0429161 ,\n",
              "              1.1003622 ,  0.7480314 ,  0.9682184 ,  0.6860839 ,  0.7529052 ,\n",
              "              0.4824298 ,  0.68847007, -0.03649583,  0.77936864,  0.44252712,\n",
              "              0.37283888,  0.91567975,  0.8737414 ,  0.7727108 ,  0.65836394,\n",
              "              0.6125599 ,  0.90100145,  0.7371663 ,  0.7953912 ,  0.77414674,\n",
              "              0.05478366,  0.9630825 ,  0.93980145,  0.9971568 ,  0.8193341 ,\n",
              "              0.8275355 ,  0.07531951,  0.6847949 ,  0.31505635,  0.7726198 ,\n",
              "              0.69524556,  0.84881866,  0.5308264 ,  0.96131283,  0.7778022 ,\n",
              "              0.9952182 ,  0.6176869 ,  0.7322245 ,  0.8122442 ,  0.6378741 ,\n",
              "              0.9089685 ,  0.52894217,  0.05814324,  0.25097308,  0.4892636 ,\n",
              "              0.87949014,  0.8861005 ,  0.45813647,  1.0301436 ,  0.48055673,\n",
              "              1.081383  ,  0.70706123,  0.35106692,  0.94062823,  1.1634164 ,\n",
              "              0.4562247 ,  0.6945022 ,  0.8003249 ,  0.6652454 ,  0.76891136,\n",
              "              0.15994735,  0.12774366,  0.8315984 ,  0.7098235 ,  0.8633015 ,\n",
              "              0.30851516,  0.95444167,  1.0401714 ,  0.7792058 ,  0.79943687,\n",
              "              0.75934047,  0.27009043,  0.81726754,  0.98279047,  0.9708885 ,\n",
              "              0.9911341 ,  0.80337906,  1.1020207 ,  1.0485117 ,  0.8686924 ,\n",
              "              1.0279393 ,  0.8081501 ,  0.9684878 ,  0.9500147 ,  1.1621909 ,\n",
              "              0.8803119 ,  1.0560502 ,  1.038198  ,  1.0133389 ,  0.9757287 ,\n",
              "              1.0183189 ,  1.0183862 ,  0.9331653 ,  1.0377877 ,  0.90380716,\n",
              "              1.123347  ,  0.8574885 ,  0.86569583,  0.95881456,  0.9264178 ,\n",
              "              0.92245024,  0.89891785,  1.034867  ,  0.9917758 ,  1.0201321 ,\n",
              "              0.74404466,  0.90124965,  0.6941103 ,  1.152563  ,  1.0302852 ,\n",
              "              1.0945802 ,  0.985577  ,  0.97712517,  0.9577923 ,  0.9644031 ,\n",
              "              1.0945704 ,  0.8284613 ,  0.97025406,  0.9324377 ,  1.2415936 ,\n",
              "              1.0110682 ,  0.8310791 ,  0.9019512 ,  0.9074723 ,  0.6560403 ,\n",
              "              1.1739571 ,  0.9337356 ,  1.2826331 ,  0.8593407 ,  0.97504276,\n",
              "              0.8674941 ,  0.85696065,  1.1191304 ,  1.0047697 ,  0.925482  ,\n",
              "              0.82461834,  1.0234402 ,  1.0355417 ,  0.8066344 ,  0.9555111 ,\n",
              "              1.0190942 ,  0.98585653,  0.9602014 ,  0.78506   ,  0.9605544 ,\n",
              "              1.0075821 ,  0.93525916,  0.7691928 ,  0.8685239 ,  0.6891485 ,\n",
              "              0.8215058 ,  1.1192179 ,  0.9449533 ,  0.75062513,  1.290211  ,\n",
              "              1.2108295 ,  1.067922  ,  0.7286969 ,  0.99922985,  0.8088233 ,\n",
              "              0.70264196,  1.0225124 ,  1.0180515 ,  0.941535  ,  0.9735746 ,\n",
              "              0.9563    ,  1.1169916 ,  0.9534073 ,  1.0018252 ,  0.8713606 ,\n",
              "              0.9825747 ,  1.1876012 ,  0.8075765 ,  0.9949137 ,  0.99147457,\n",
              "              0.45257232,  1.1143553 ,  1.1770159 ,  1.1898142 ,  0.9754092 ,\n",
              "              1.0466411 ,  0.7806979 ,  0.81983656,  0.9063115 ,  0.9756018 ,\n",
              "              0.97892326,  0.8128855 ,  0.72288245,  1.2673619 ,  0.8918243 ,\n",
              "              0.984064  ,  0.8873797 ,  0.88248265,  0.9681033 ,  1.0019083 ,\n",
              "              1.0843676 ,  0.95790404,  0.799105  ,  1.0675317 ,  1.0526549 ,\n",
              "              0.97763216,  0.87461144,  0.9447302 ,  0.74993885,  0.97390795,\n",
              "              1.654638  ,  1.0504663 ,  0.78925353,  1.13901   ,  1.3548429 ,\n",
              "              0.9741306 ,  1.3727907 ,  1.1680789 ,  0.8711522 ,  0.8112649 ,\n",
              "              0.79739463,  1.2729534 ,  0.98385537,  1.5018182 ,  0.87356925,\n",
              "              0.8138914 ,  2.0350318 ,  1.041104  ,  0.87982965,  0.89309454,\n",
              "              1.3922273 ,  0.9872634 ,  0.911251  ,  1.3654604 ,  1.6220708 ,\n",
              "              0.69902956,  0.99224156,  1.0657678 ,  1.0203073 ,  0.85414445,\n",
              "              1.2814045 ,  1.2259116 ,  1.0153188 ,  1.5189432 ,  1.0078174 ,\n",
              "              1.0649292 ,  1.4627622 ,  0.9353435 ,  1.0497195 ,  0.8511452 ,\n",
              "              0.9661116 ,  0.8315072 ,  0.91804093,  0.96472454,  1.1757718 ,\n",
              "              0.7781552 ,  1.4496042 ,  1.3220475 ,  1.2475545 ,  1.5268438 ,\n",
              "              1.406827  ,  1.3483112 ,  0.9241933 ,  0.9676526 ,  0.9818683 ,\n",
              "              0.89570606,  1.4091312 ,  0.91336876,  1.6534717 ,  0.8740968 ,\n",
              "              1.5067245 ,  1.121186  ,  0.95296776,  1.4516047 ,  0.902822  ,\n",
              "              0.9979807 ,  0.98308444,  0.9253368 ,  1.0391308 ,  0.9376867 ,\n",
              "              0.8358062 ,  1.5070012 ,  0.87929666,  0.9347398 ,  1.0741981 ,\n",
              "              0.90756375,  0.8705177 ,  1.3567142 ,  1.5002075 ,  1.38084   ,\n",
              "              0.9993019 ,  0.7966347 ,  0.87836385,  1.1874652 ,  0.9678011 ,\n",
              "              0.99225205,  0.9570247 ,  0.9138081 ,  0.7697503 ,  1.2307276 ,\n",
              "              1.0543513 ,  1.0790589 ,  0.78723764,  1.3916996 ,  1.4623665 ,\n",
              "              1.2879078 ,  1.0576271 ,  1.440128  ,  1.339391  ,  1.0804397 ,\n",
              "              0.874935  ,  1.1054215 ,  1.3409855 ,  1.5875199 ,  0.76516885,\n",
              "              1.644156  ,  1.316108  ,  0.9335892 ,  1.1070862 ,  1.1206286 ,\n",
              "              1.0519298 ,  1.6412535 ,  1.3672315 ,  1.0074878 ,  0.9084727 ,\n",
              "              0.9310122 ,  1.5835509 ,  0.8602258 ,  1.0274632 ,  1.2672911 ,\n",
              "              1.0032716 ,  0.9874799 ,  1.5264033 ,  0.77898556,  0.6549934 ,\n",
              "              0.61149186,  0.83701146,  0.78318757,  1.040473  ,  0.78023684,\n",
              "              0.8413978 ,  0.67482805,  0.90133005,  0.91968936,  1.0286336 ,\n",
              "              0.9021895 ,  0.8521967 ,  0.76525486,  0.8234952 ,  0.8261558 ,\n",
              "              0.8121345 ,  1.1238625 ,  0.8446348 ,  0.97933143,  0.8878793 ,\n",
              "              0.794579  ,  0.90644306,  0.81224525,  1.2637261 ,  0.8326924 ,\n",
              "              0.76762754,  0.78527975,  1.0981193 ,  0.833159  ,  0.74576765,\n",
              "              0.67643315,  0.8789227 ,  0.8792702 ,  1.0069078 ,  0.57977325,\n",
              "              0.64874977,  0.900639  ,  0.7781562 ,  0.76427716,  0.7594572 ,\n",
              "              0.79017997,  0.86135644,  1.0164263 ,  0.6714426 ,  0.7997341 ,\n",
              "              0.733994  ,  0.7802043 ,  1.0080678 ,  0.87752616,  0.95566595,\n",
              "              0.99745846,  0.74922526,  0.9258136 ,  0.8814952 ,  1.1348374 ,\n",
              "              0.8504358 ,  0.86065596,  0.7278019 ,  0.85257244,  0.9671358 ,\n",
              "              0.7706166 ,  1.0031607 ,  0.7244804 ,  1.0159642 ,  0.9255961 ,\n",
              "              0.65259075,  0.9896053 ,  0.7133157 ,  0.78388137,  0.7683284 ,\n",
              "              0.7040165 ,  0.77527726,  0.801625  ,  0.8248095 ,  1.2003404 ,\n",
              "              0.7760042 ,  0.9149343 ,  0.76729995,  0.77516395,  0.87227446,\n",
              "              1.1166253 ,  0.97763497,  0.99880743,  0.6266357 ,  0.6486685 ,\n",
              "              0.822242  ,  0.99043095,  0.7575317 ,  0.881665  ,  0.96242285,\n",
              "              0.8158164 ,  0.93281716,  0.854246  ,  0.940534  ,  0.831679  ,\n",
              "              0.8444236 ,  1.1937814 ,  1.1327015 ,  1.0935777 ,  0.912407  ,\n",
              "              1.2979066 ,  0.98696655,  0.8253552 ,  0.7162002 ,  0.93704164,\n",
              "              0.9057634 ,  1.0766442 ,  0.6325626 ,  0.9494423 ,  0.93419594,\n",
              "              0.82989633,  0.7831992 ,  0.93416524,  0.8473062 ,  1.0796278 ,\n",
              "              0.8934414 ,  0.9026163 ,  1.0981617 ,  0.7821827 ,  1.1304301 ,\n",
              "              0.9212775 ,  0.99427885,  0.94435924,  0.67558557,  0.64942086,\n",
              "              1.1377777 ,  0.8204544 ], dtype=float32)),),\n",
              "    ()),\n",
              "   (),\n",
              "   ()),\n",
              "  {'__marker_for_cached_weights_': ()}),\n",
              " (((), (((), ((), ())), ((), ()), ()), (), ()),\n",
              "  {'__marker_for_cached_state_': ()}))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
        "    \"\"\"Function to test the accuracy of the model.\n",
        "\n",
        "    Args:\n",
        "        test_Q1 (numpy.ndarray): Array of Q1 questions.\n",
        "        test_Q2 (numpy.ndarray): Array of Q2 questions.\n",
        "        y (numpy.ndarray): Array of actual target.\n",
        "        threshold (float): Desired threshold.\n",
        "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
        "        vocab (collections.defaultdict): The vocabulary used.\n",
        "        data_generator (function): Data generator function. Defaults to data_generator.\n",
        "        batch_size (int, optional): Size of the batches. Defaults to 64.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model.\n",
        "    \"\"\"    \n",
        "    \n",
        "    \n",
        "    accuracy = 0\n",
        "    for i in range(0, len(test_Q1), batch_size):\n",
        "        q1, q2 = next(data_generator(test_Q1[i:i + batch_size], test_Q2[i:i + batch_size], batch_size, vocab['<PAD>'], shuffle=False))\n",
        "        y_test = y[i:i + batch_size]\n",
        "        v1, v2 = model([q1,q2])\n",
        "\n",
        "        for j in range(batch_size):\n",
        "\n",
        "            d = np.dot(v1[j],v2[j])   \n",
        "            res =  d > threshold  \n",
        "            accuracy +=  (y_test[j] == res) \n",
        "\n",
        "    accuracy = accuracy  / len(test_Q1)\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "9Lkv287zCxi9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model, vocab, batch_size = 512) \n",
        "print(\"Accuracy\", accuracy)"
      ],
      "metadata": {
        "id": "rL9YAmZaC2eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79292fe5-2981-44b4-c632-38de3fbd7db3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.72646484375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "3DA2lU9pC31z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n",
        "    \"\"\"Function for predicting if two questions are duplicates.\n",
        "\n",
        "    Args:\n",
        "        question1 (str): First question.\n",
        "        question2 (str): Second question.\n",
        "        threshold (float): Desired threshold.\n",
        "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
        "        vocab (collections.defaultdict): The vocabulary used.\n",
        "        data_generator (function): Data generator function. Defaults to data_generator.\n",
        "        verbose (bool, optional): If the results should be printed out. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the questions are duplicates, False otherwise.\n",
        "    \"\"\"\n",
        "    q1 = nltk.word_tokenize(question1)  # tokenize\n",
        "    q2 = nltk.word_tokenize(question2) # tokenize\n",
        "    Q1, Q2 = [], []\n",
        "    for word in q1: \n",
        "        Q1 += [vocab[word]]\n",
        "    for word in q2:  # encode q2\n",
        "        Q2 += [vocab[word]]\n",
        "    \n",
        "    Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\n",
        "    # Call the model\n",
        "    v1, v2 = model([Q1, Q2])\n",
        "    d =  np.dot(v1,v2.T)   \n",
        "    res = d > threshold  \n",
        "\n",
        "    \n",
        "    if(verbose):\n",
        "        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
        "        print(\"d   = \", d)\n",
        "        print(\"res = \", res)\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "kWiz0-LQC4mi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to try with your own questions\n",
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "# 1/True means it is duplicated, 0/False otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose = True)"
      ],
      "metadata": {
        "id": "oZj5T65AC_uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc90590-21de-4f6e-f7ab-c8406f3ab988"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1  =  [[585  76   4  46  53  21   1   1]] \n",
            "Q2  =  [[ 585   33    4   46   53 7280   21    1]]\n",
            "d   =  [[0.8585515]]\n",
            "res =  [[ True]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Threshold variation\n",
        "\n",
        "Distance evaluate using cosinus similarity, let's see how the threshold influence the accuracy"
      ],
      "metadata": {
        "id": "vn4akzL7jyV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.arange(0.1, 1, 0.1).tolist()\n",
        "accuracy = []\n",
        "for i in threshold:\n",
        "  acc_t = classify(Q1_test,Q2_test, y_test, i , model, vocab, batch_size = 512) \n",
        "  accuracy.append(acc_t)\n",
        "  print(\"Accuracy with a threshold of \",  str(i) ,\" is\", str(acc_t))\n",
        "\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBkix1ZMj219",
        "outputId": "ffbf28c6-4ac0-413a-e642-5ebfb35b7bc3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with a threshold of  0.1  is 0.45380859375\n",
            "Accuracy with a threshold of  0.2  is 0.49912109375\n",
            "Accuracy with a threshold of  0.30000000000000004  is 0.55146484375\n",
            "Accuracy with a threshold of  0.4  is 0.6048828125\n",
            "Accuracy with a threshold of  0.5  is 0.6595703125\n",
            "Accuracy with a threshold of  0.6  is 0.7033203125\n",
            "Accuracy with a threshold of  0.7000000000000001  is 0.72646484375\n",
            "Accuracy with a threshold of  0.8  is 0.7197265625\n",
            "Accuracy with a threshold of  0.9  is 0.67978515625\n",
            "[0.45380859375, 0.49912109375, 0.55146484375, 0.6048828125, 0.6595703125, 0.7033203125, 0.72646484375, 0.7197265625, 0.67978515625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(threshold, accuracy)\n",
        "plt.title('Accuracy depending on the threshold')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "9OgmIcZPk1_n",
        "outputId": "8af80de1-c102-4eb2-cd93-1c837e7f0fc2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OO80hCwl_yF",
        "outputId": "10ffaa07-fd20-4720-c658-f4e4a4cbb65f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45380859375, 0.49912109375]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPFGxSY1mNDm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "siamese-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "dc2cac48a6e899fdd6c9809df7b513f32045676c07a31454dd4ee8f14379150e"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}